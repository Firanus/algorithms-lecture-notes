# 11.4 - Hash Table Context

In this final note for lecture 11, we'll look at some of the context surrounding hashing in practical implementations.

## String `hashCode()` in Java 1.1

When looking at Java 1.1, it's designers found that the cost of calculating the hash function for long strings seemed excessive. They resolved to only examine 8-9 evenly spaced characters. This had the benefit of saving time in performing the arithmetic.

```Java
public int hashCode() { 
  int hash = 0;
  int skip = Math.max(1, length() / 8)
  for (int i = 0; i < length(); i += skip)
    hash = s[i] + (37 * hash);
  return hash;
}
```

Unfortunately, the results of this move were that there was the potential for really bad collision patterns on typical data. E.g. if you were using URLs as your input keys, it was entirely possible that for similar URLs, you'd consider exactly the same group of characters. As a result, the performance of the symbol table took a big hit.

This story shows that it is important to use all the data of your input when calculating the hash function. If an analysis does show that calculating the hash function is time-consuming, then it might be worth considering an alternative data structure like red-black trees, even for just implementing search and insert.

## Algorithmic Complexity Attacks

> Q: Is the uniform hashing assumption important in practice?

> A: In systems where consistent performance is absolutely critical, yes, it is. For example, aircraft control, nuclear reactors or pacemakers.

> A: Surprising situations: Denial-of-service attacks. Java publishes its hash functions online, so it's possible that a malicious adversary could learn your hash function and cause a big pile-up in a single slot to grind performance to a halt.
 
There are also various real-world exploits, where certain collections of bits can cause different systems to crash. With a little research, you can find collections of keys with the same hash code (e.g. "Aa" and "BB"), and then combine those keys together to produce an exponentially large number of keys with the same hash. See [Crosby-Wallach 2003] for more info.

These are all cases where the guaranteed performance of red-black trees might be worth looking into.

## Diversion: one-way hash functions

As an aside, there's a subset of hash functions called one-way hash functions which have very important implications for commerce and cryptography.

The idea behind these hash functions is that it's easy to calculate the hash, but very difficult to reverse-engineer the key from the original hash. In turn, it also very difficult to find two keys that hash to the same value. These functions are the basis of cryptographic methods like the use of public and private keys in RSA.

Known one way hash functions include MD4, MD5, SHA-0, SHA-1 (all of which are now known to be insecure), SHA-2, WHIRLPOOL, RIPEMD-160 etc.

Applications include digital fingerprints, messsage digest and storing passwords.

Unfortunately the caveat of these methods is that they're too expensive for use in symbol table applications.

## Separate Chaining vs. Linear Probing

Both separate chaining and linear probing have their pros and cons:

Separate Chaining:
* Easier to implement delete
* Performance degrades gracefully
* Clustering less sensitive to poorly-designed hash functions

Linear probing:
* Less wasted space
* Better cache performance

There are a few questions we haven't considered, namely how do we delete items, and how do we resize them? These are all exercises it'd be useful for the reader to go and work out for themselves.

## Hashing: Variants on the theme

Many improvements to hashing have been studied.

#### Two-probe hashing (separate chaining variant)
* Hash to two positions, insert key in shorter of two chains
* Reduces expected length of longest chain to log log N.

#### Double hashing (linear probing variant)
* Use linear probing, but skip a variable amount, not just 1 each time
* Effectively eliminates clustering
* Can allow table to become nearly full
* More difficult to implement delete.

#### Cuckoo hashing (linear probing variant)

* Hash key to two positions, insert key into either position. If occupied, reinsert displaced key into its alternative position recursively.
* Constant worst case time for search

## Hash Tables vs. Balanced Search Trees

Again, both have their advantages and disadvantages.

Hash Tables:
* Simpler to code
* No effective alternative for unordered keys (i.e. no compareTo function)
* Faster for simple keys (a few arithmetic ops vs. log N compares)
* Better system support in Java for strings (e.g. cached hash code)

Balanced Search Trees
* Stronger performance guarantee
* Support for ordered ST operations
* Easier to implement `compareTo()` correctly than `equals()` and `hashCode()`

The Java system actually includes both options and leaves it up to the user to decide what's best for them:
* Red-black BSTs: `java.util.TreeMap`, `java.util.TreeSet`
* Hash Tables: `java.util.HashMap`, `java.util.IdentityHashMap`