# 9.0 - Balanced Search Trees

To review where we were at the end of the last lecture, we had a look at binary search trees. If you have random insertions, these give average case insertion and search proportional to log N. Deletion is a more complex matter, and often ends up being proportional to sqrt N. And in all of these cases, if you enter the items into the BST in order (a relatively common scenario), all 3 operations performance goes to the worst case, proportional to N.

Our goal is to have all 3 of these operations have worst case performance proportional to O(log N).

In this lecture we'll look at an algorithm called 2-3 trees, and a data structure called left-leaning red-black BSTs that help us reach this goal. Finally, we'll also look at a generalisation of these structures called B-trees.

## 2-3 Tree

A 2-3 tree is a way to generalise BSTs to provide us with the flexibility we need to guarantee performance. In particular, 2-3 trees allow us to have either **1 or 2 keys per node**. You are then allowed two types of node:
* **2-node**: One key, Two children. One child contains keys *less* than the original, while the other contains *greater* keys.
* **3-node**: Two keys, Three children. We retain the *less* and *greater* children, and also introduce a child with keys *in-between* the two keys.

Regular BSTs, as you can see, are 2-3 trees.

2-3 trees also have 2 other important properties: **Perfect Balance** and **Symmetric Order**.
* In a **perfectly balanced** tree, every path from root to a null link has the same length.
* In a tree with **symmetric order**, an inorder traversal yields keys in ascending order.

### Searching in a 2-3 tree

The algorithm for searching a 2-3 tree is relatively simple:

1. Compare the search key against keys in the node.
2. Find the interval containing the search key
3. Follow the associated link recursively.

![Searching a 2-3 tree](https://algs4.cs.princeton.edu/33balanced/images/23tree-search.png)

Thanks to the property of perfect balance, the maximum time a search can take is proportional to log N.

### Inserting into a 2-3 tree

There are several cases here we need to consider in order to maintain perfect balance.

#### Inserting into a 2-node at the bottom of the tree

This is the simplest case. We search as normal, and when we reach the 2-node at the bottom of the tree, we simply add our key to it and make it a 3-node.

#### Inserting into a 3-node at the bottom

Here, we again search as normal to find the 3-node we want to insert into. Then, we:

1. Add our new key into the 3-node to make it a temporary 4-node.
2. Break our temporary 4 node into 2 2-nodes (one for each of the smallest and greatest element in the 4-node). The middle element of the old 4-node is then inserted into the parent 2-node.
3. The links between the parent node and the 2 new children nodes are updated to ensure the tree is properly ordered.

![Inserting into a 2-3 tree](https://algs4.cs.princeton.edu/33balanced/images/23tree-insert3b.png)

The assumption in this case is that the parent node of the 3-node we want to insert into is a 2-node. Having said that, if the parent were itself a 3-node, you can apply this same procedure recursively up to the top of the tree. However,

4. If you get to the root, and it becomes a 4-node, you then break it into 3 2-nodes. The middle key becomes the new root, and the smaller and greater elements become its children. Note that this is the only time the height of a 2-3 tree changes.

![Inserting into a full 2-3 tree](https://algs4.cs.princeton.edu/33balanced/images/23tree-split.png)

### Local Transformations in a 2-3 tree

An imporatant point to note from the above: splitting a 4-node is a local transformation - it takes a constant number of operations. Regardless of where you find a 4-node on the tree, the ability to bunch up the keys beneath it into finite sub-trees means we can guarantee that splitting any specific 4-node will take constant time. When we do our performance analysis, we will see that this detail is critical in establishing the performance of the tree.

### Global Properties in a 2-3 tree

As stated earlier, we require our 2-3 trees to have symmetric order and perfect balance. How do we guarantee that these properties are satisfied? All we have to do is confirm that each transformation maintains both symmetric order and perfect balance. The following diagram shows all the available operations.

![Local Tranformations in a 2-3 tree](http://apprize.info/science/algorithms_1/algorithms_1.files/image259.jpg)

As the diagram shows, all the individual variants of insertion in a 2-3 tree (is the parent 2 or 3, and is the inserted element less than, greater than, or in between the parent keys) maintain these two properties. Thus, as we construct a 2-3 tree, we can guarantee by induction that the properties are maintained at every stage. Because a 2-3 tree with only 1 item definitionally is symmetrically ordered and has perfect balance, we can guarantee that 2-3 trees have the defined global properties.

### 2-3 Tree Performance

These properties make it very easy to gauge the performance of our trees. Both search and insertion are proportional to the height of the 2-3 tree. That height is clearly bounded:

* Worst-case (all nodes are 2-nodes): lg N
* Best-case (all nodes are 3-nodes): .631 lg N

Thus, we can guarantee that both search and insertion take O(lg N) time in the worst-case.

### Implementation?

How do we go about implementing a 2-3 tree? Well, it turns out that implementing it exactly as described above is something of a pain. For instance:
* Maintaining multiple node types is cumbersome
* Need multiple compares to move down the tree
* You need to move back up the tree to split 4-nodes
* Large number of cases that cause splitting.

In essence, we could implement the 2-3 as described, but there's a better way to go about it. This is where our **red-black trees** come in. We'll take a look at them in the next note.