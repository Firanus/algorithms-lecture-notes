# 11.2 - Separate Chaining

In this note we'll take a look at Separate Chaining, a collision resolution strategy that makes use of linked lists.

## Collisions

How do we handle the situation where two distinct keys hash to the same index?

The birthday problem from combinatorial geometry tells us that this is basically guaranteed to happen unless you have a ridiculous amount of memory. And the coupon collector and load balancing problems tell us that the collisions will be evenly distributed.

Our challenge then is to deal with collisions efficiently.

## Separate Chaining Symbol Table

The separate chaining solution to this problem (which dates back to 1953) involves using an array of M < N linked lists. Our process then is to:

1. **Hash** - Map your key to an integer `i` between 0 and M-1
2. **Insert** - Put that key at the front of the ith chain (if it isn't already there)
3. **Search** - is then only a matter of searching the ith chain.

### Code implementation

```Java
public class SeparateChainingHashST<Key, Value> {
  private int M = 97; // Number of chains
  private Node[] st = new Node[M]; // array of chains
  
  private static class Node {
    private Object key; // We're not allowed generic array creation.
    private Object val; // So these have to be objects.
    private Node next;
    // ...
  }
  
  private int hash(Key key) { 
    return (key.hashCode() & 0x7fffffff) % M;  
  }
  
  public Value get(Key key) {
    int i = hash(key);
    for (Node x = st[i]; x != null; x = x.next)
      if (key.equals(x.key)) return (Value) x.val;
    return null;
  }
  
  public Void put(Key key, Value val) {
    int i = hash(key);
    for (Node x = st[i]; x != null; x = x.next)
      if (key.equals(x.key)) {
        x.val = val;
        return;
      }
    st[i] = new Node(key, val, st[i]);
  }
}
```

## Analysis

Under the uniform hashing assumption, the probability that the number of keys in a list is within a constant factor of N / M is extremely close to 1.

Thus, we've effectively divided our search cost by M.

How big do we make M? Well:
* **M too large** => too many empty chains
* **M too small** => chains too long
* **Typically**: M ~ N / 5 => constant time ops.

Note that if we want to go from an empty hash table to a hash table with a very large amount of data and then back to empty, it'd be important to apply array-resizing to keep M ~ N / 5.

Thus, we have a data structure with effectively constant search, insert and delete functions. Comparing it with red-black trees, we'd go for hash tables if:
* Short keys where it's not particularly difficult to compute the hashes.
* We don't need ordered iteration or any of the ordered operations.