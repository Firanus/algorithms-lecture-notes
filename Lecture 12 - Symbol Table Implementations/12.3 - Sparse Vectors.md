# 12.3 - Sparse Vectors

Finally, we'll take a look at a mathematical client: implementing sparse vectors in matrices.

## Matrix Vector Multiplication

Normal matrix-vector multiplication is relatively straightforward, and we won't go through the rigamarole of redefining it here.

To implement the equation `Ax = b` where `A` is a matrix and `x` and `b` are column vectors, we would use the following code:

```Java
// ...
double[][] a = new double[N][N];
double[] x = new double[N];
double[] b = new double[N];
// ...

double sum;
for (int i = 0; i < N; i++) {
  sum = 0.0;
  for (int j = 0; j < N; j++)
    sum += a[i][j] * x[j];
  b[i] = sum;
}
```

You'll notice that the nested loops give this simple operation a runtime of O(N^2). This is fine in typical applications where the matrix is small, or very full.

However, often we'll have to perform multiplication with matrices where most of the entries are zero. In this case we can use Symbol Tables to reduce the runtime significantly.

## Sparse Vector Multiplication

The assumptions we'll make for this problem are that:
* Matrix dimension is 10,000
* Average non-zeros per row ~ 10

We can use these to make a number of optimizations.

### Vector Representations

First, we'll optimise how we store our vectors.

The normal implementation of a vector is to use a 1D array. This has constant time access to the elements, and takes up space *proportional to N*.

If we use a symbol table representation, where:
* `Key` = Index
* `Value` = Entry

Then we have a representation that takes up space *proportional to number of non-zeros*, and which also has a more efficient iterator.

#### Code Implementation

```Java
public class SparseVector {
  private HashST<Integer, Double> v; // Hash because order not important
  
  public SparseVector() { 
    v = new HashST<Integer, Double>(); 
  }
  
  public void put (int i, double x) { 
    v.put(i, x); 
  }
  
  public double get(int i) {
    if   (!v.contains(i)) return 0.0;
    else                  return v.get(i);
  }
  
  public Iterable<Integer> indices() {
    return v.keys();
  }
  
  public double dot(double[] that) {
    double sum = 0.0;
    for (int i: indices())
      sum += that[i] * this.get(i);
    return sum;
  }
}
```

Notice here that our dot product here is not proportional to N, but rather to the number of non-zero entries in the sparse vector.

### Matrix representations

We can make a similar optimization to our arrays.

The normal implementation of an array is to use a 2D array, where each row of the matrix is itself an array. This gives us constant time access to the elements, and takes up a space *proportional to N^2*.

If, instead, we represent our matrix as an array of sparse vectors, we again optimise it. Not, we still retain constant time access to our elements (remember we were using a HashST, which has average-case constant time access costs), but the space taken up is proportional to the number of non-zero entries in the matrix. We can also utilise the more efficient iterator of the sparse vector.

### Sparse Matrix-Vector Multiplication

```Java
// ...
SparseVector[] a = new SparseVector[N];
double[] x = new double[N];
double[] b = new double[N];
// ...
// Initialise a[] and x[]
//... 
for (int i = 0; i < N; i++)
  b[i] = a[i].dot(x);
```

Thus, our running time become O(N * n) where `n` is the average number of entries in each row. Under the assumptions we made initially, we've made a quadratic algorithm have near-linear performance (it is 1000x faster), which is a considerable improvement.