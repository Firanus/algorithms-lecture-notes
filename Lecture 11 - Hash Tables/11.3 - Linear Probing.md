# 11.3 - Linear Probing

Another popular collision resolution algorithm is called Linear Probing, which will look at in this note.

This algorithm was introduced in 1953, around the same time as the Separate Chaining algorithm

## Open Addressing

The basic idea with linear probing is that when a new key collides, find the next empty slot and put it there.

In this case, the size of the array needs to be bigger than the number of keys we expect the table to contain. We use empty slots in the array to shorten the length of the array we need to search when we do a `get`.

Our process is:

1. **Hash** - Map key to integer `i` between 0 and `M-1`
2. **Insert** - Put at table index `i` if free; if not, try `i+1`, `i+2` etc. (and wrap around to the beginning) until you find an empty spot.

This process will lead to "clusters" of keys forming around common hashes. Clearly, we want to keep those clusters small. We achieve this by simply not putting too much data into the table. Our search operation naturally falls out of all this:

3. **Search** - To search, we again hash the key, and then search at table index `i`. If the key is occupied but not a match, we continue iterating through to the end of the cluster.

**NOTE** - The array size `M` *must* be greater than the number of key-value pairs N. Thus, including array resizing logic is pretty much a requirement.

## Code Implementation

Below is a code implementation of linear probing. Note that the code for doubling and halving the size of the array has been omitted for brevity.

```Java
public class LinearProbingHashST<Key, Value> {
  private int M = 30001;
  private Value[] vals = (Value[]) new Object[M];
  private Key[] keys = (Key[]) new Object[M];
  
  private int hash(Key key) {
    return (key.hashCode() & 0x7fffffff) % M;
  }
  
  public void put(Key key, Value val) {
    int i;
    for (i = hash(key); keys[i] != null; i = (i+1) % M)
      if (keys[i].equals(key))
        break;
    keys[i] = key;
    vals[i] = val;
  }
  
  public Value get(Key key) {
    int i;
    for (i = hash(key); keys[i] != null; i = (i+1) % M)
      if (key.equals(keys[i])) 
        return vals[i];
    return null;
  }
}
```

## Historical Context

In ancient times, memory and bits were really valuable, so people were very keen to minimise the number of empty spaces in a table. As a result, a lot of effort was put into working out just how full we could get a hash table using linear probing without sacrificing performance.

If we observe the linear probing algorithm at work, one of the first observation we make is that when you introduce new keys, they're likely to hash into the middle of big clusters. That in turn makes big clusters even bigger.

### Knuth's Parking Problem

Indeed, Knuth studied this problem at length. The problem can be phrased as:

> Cars arrive ar a one-way street with M parking spaces. Each car desires a random space `i`. If space `i` is taken, try `i+1`, `i+2` etc.
> 
> What is the mean displacement of the car from its desired parking spot?
> 

This problem can be solved using a (complicated) balls-and-bins probabalistic analysis. The results of the analysis is that: 
* With M/2 cars, mean displacement ~ 3 / 2
* With M cars, mean displacement ~ sqrt(pi * M / 8)

So we go from a constant displacement to a displacement proportional to sqrt(M).

In the lecture, Professor Sedgewick presents a slightly more precise mathematical analysis, but the details are unimportant for understanding this problem, so we've omitted them from here.

## Analysis Summary

* **M too large** => too many empty array entries
* **M too small** => search time blows up
* **Typical choice** => M ~ 2N